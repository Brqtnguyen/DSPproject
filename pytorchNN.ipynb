{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os \n",
    "from thop import profile\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Gender        Age    Height      Weight family_history_with_overweight  \\\n",
      "0   0    Male  24.443011  1.699998   81.669950                            yes   \n",
      "1   1  Female  18.000000  1.560000   57.000000                            yes   \n",
      "2   2  Female  18.000000  1.711460   50.165754                            yes   \n",
      "3   3  Female  20.952737  1.710730  131.274851                            yes   \n",
      "4   4    Male  31.641081  1.914186   93.798055                            yes   \n",
      "\n",
      "  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
      "0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
      "1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
      "2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
      "3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
      "4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
      "\n",
      "        TUE       CALC                 MTRANS           NObeyesdad  \n",
      "0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n",
      "1  1.000000         no             Automobile        Normal_Weight  \n",
      "2  1.673584         no  Public_Transportation  Insufficient_Weight  \n",
      "3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n",
      "4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  \n",
      "      id  Gender        Age    Height      Weight  \\\n",
      "0  20758    Male  26.899886  1.848294  120.644178   \n",
      "1  20759  Female  21.000000  1.600000   66.000000   \n",
      "2  20760  Female  26.000000  1.643355  111.600553   \n",
      "3  20761    Male  20.979254  1.553127  103.669116   \n",
      "4  20762  Female  26.000000  1.627396  104.835346   \n",
      "\n",
      "  family_history_with_overweight FAVC      FCVC       NCP       CAEC SMOKE  \\\n",
      "0                            yes  yes  2.938616  3.000000  Sometimes    no   \n",
      "1                            yes  yes  2.000000  1.000000  Sometimes    no   \n",
      "2                            yes  yes  3.000000  3.000000  Sometimes    no   \n",
      "3                            yes  yes  2.000000  2.977909  Sometimes    no   \n",
      "4                            yes  yes  3.000000  3.000000  Sometimes    no   \n",
      "\n",
      "       CH2O SCC       FAF       TUE       CALC                 MTRANS  \n",
      "0  2.825629  no  0.855400  0.000000  Sometimes  Public_Transportation  \n",
      "1  3.000000  no  1.000000  0.000000  Sometimes  Public_Transportation  \n",
      "2  2.621877  no  0.000000  0.250502  Sometimes  Public_Transportation  \n",
      "3  2.786417  no  0.094851  0.000000  Sometimes  Public_Transportation  \n",
      "4  2.653531  no  0.000000  0.741069  Sometimes  Public_Transportation  \n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "random_seed = 42\n",
    "g = torch.Generator()\n",
    "g.manual_seed(random_seed)\n",
    "\n",
    "train_dataset=pd.read_csv(os.getcwd()+'/dataset/train.csv')\n",
    "test_dataset=pd.read_csv(os.getcwd()+'/dataset/test.csv')\n",
    "\n",
    "print(train_dataset.head(5))\n",
    "print(test_dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,generator=g)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1454",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1454",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_features, train_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_features\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_labels\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\BQTX\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1454"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start: ', time.time())\n",
    "\n",
    "train_time = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    #break;\n",
    "\n",
    "    start_train = time.time()\n",
    "\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_loss = 0\n",
    "    # Sets the model in training mode.\n",
    "    model = model.train()\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "        # TODO: Put the images and labels on the GPU\n",
    "        images = images.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "        labels = labels.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "        # Sets the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # The actual inference\n",
    "        outputs = model(images)\n",
    "        # Compute the loss between the predictions (outputs) and the ground-truth labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Do backpropagation to update the parameters of your model\n",
    "        loss.backward()\n",
    "        # Performs a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        # The outputs are one-hot labels, we need to find the actual predicted\n",
    "        # labels which have the highest output confidence\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        # Print every 100 steps the following information\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx == 389):\n",
    "            print('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f Acc: %.2f%%' % (epoch + 1, num_epochs, batch_idx + 1,\n",
    "                                                                             len(train_dataset) // batch_size,\n",
    "                                                                             train_loss / (batch_idx + 1),\n",
    "                                                                             100. * train_correct / train_total))\n",
    "    \n",
    "    train_time = train_time + time.time() - start_train\n",
    "\n",
    "    # Testing phase\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_loss = 0\n",
    "    # Sets the model in evaluation mode\n",
    "    model = model.eval()\n",
    "    # Disabling gradient calculation is useful for inference.\n",
    "    # It will reduce memory consumption for computations.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(test_loader)):\n",
    "            # TODO: Put the images and labels on the GPU\n",
    "\n",
    "            images = images.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "            labels = labels.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "            # Perform the actual inference\n",
    "            outputs = model(images)\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            # The outputs are one-hot labels, we need to find the actual predicted\n",
    "            # labels which have the highest output confidence\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "    print('Test loss: %.4f Test accuracy: %.2f %%' % (test_loss / (batch_idx + 1),100. * test_correct / test_total))\n",
    "\n",
    "print('End Time: ', time.time())\n",
    "\n",
    "print('\\nTotal training time: ', train_time)\n",
    "\n",
    "sample_input = torch.randn(1,3,32,32)\n",
    "sample_input = sample_input.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "macs_thop, params_thop = profile(model, inputs=(sample_input, ))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Macs from thop.profile: \", macs_thop)\n",
    "print(\"Params from thop.profile: \", params_thop)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "torchsum_out = summary(model, (3,32,32))\n",
    "\n",
    "print(torchsum_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
